{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Read in the data\n",
    "rawDF = pd.read_csv(\"Cancer_Data.csv\")\n",
    "\n",
    "# Take a peek at the data\n",
    "rawDF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'id' column as its useless to us\n",
    "rawDF = rawDF.drop([\"Unnamed: 32\",\"id\"], axis = 1)\n",
    "\n",
    "# Let's also change diagnosis into a numeric binary variable\n",
    "rawDF.diagnosis = [1 if each == \"M\" else 0 for each in rawDF.diagnosis]\n",
    "\n",
    "# Let's take a deeper look at the data and use the describe function\n",
    "rawDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also use a for loop to check for NA values\n",
    "for col in rawDF:\n",
    "    naCount = rawDF[col].isna().sum()\n",
    "    print(f\"The number of NA values in the {col} col is {naCount}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Functions\n",
    "\n",
    "# This function generates histograms for each feature to show the distribution of the data\n",
    "def generateHistograms(rawDF, column_names):\n",
    "    n_cols = 5\n",
    "    n_rows = (len(column_names) + n_cols - 1) // n_cols\n",
    "    axs = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 5))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for i, col in enumerate(column_names):\n",
    "        axs[i].hist(rawDF[col].dropna(), bins=15)\n",
    "        axs[i].set_xlabel(col, labelpad=14)\n",
    "        axs[i].set_ylabel(\"Frequency\", labelpad=14)\n",
    "        axs[i].set_title(f\"Distribution of {col}\")\n",
    "\n",
    "    for j in range(i + 1, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# This function generates boxplots for each feature to show outliers\n",
    "# That said, we may not need to worry about outliers in the context of this data\n",
    "def generateBoxplots(rawDF, column_names):\n",
    "    n_cols = 5\n",
    "    n_rows = (len(column_names) + n_cols - 1) // n_cols\n",
    "    axs = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 5))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for i, col in enumerate(column_names):\n",
    "        sns.boxplot(x=rawDF[col], ax=axs[i])\n",
    "        axs[i].set_title(f\"Boxplot of {col}\")\n",
    "\n",
    "    for j in range(i + 1, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "columns_to_plot = rawDF.columns.drop('diagnosis')\n",
    "generateHistograms(rawDF, columns_to_plot)\n",
    "generateBoxplots(rawDF, columns_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triangle Correlation Heatmap\n",
    "plt.figure(figsize=(20, 8))\n",
    "mask = np.triu(np.ones_like(rawDF.corr(), dtype=bool))\n",
    "heatmap = sns.heatmap(rawDF.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "heatmap.set_title('Triangle Correlation Heatmap', fontdict={'fontsize':18}, pad=16)\n",
    "plt.savefig('heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "\n",
    "yDF = rawDF[\"diagnosis\"]\n",
    "xDF = rawDF.drop(columns=[\"diagnosis\"], axis=1)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(\n",
    "    xDF, yDF, \n",
    "    test_size=0.05,\n",
    "    shuffle = True,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include SMOTE to handle class imbalance\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "xTrainBalanced, yTrainBalanced = smote.fit_resample(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "\n",
    "select = SelectKBest(f_classif, k=25)\n",
    "xTrainSelect = select.fit_transform(xTrainBalanced, yTrainBalanced)\n",
    "xTestSelect = select.transform(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "\n",
    "xScaler = StandardScaler()\n",
    "xTrainScaled = xScaler.fit_transform(xTrainBalanced, yTrainBalanced)\n",
    "xTestScaled = xScaler.transform(xTestSelect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Hyperparameter Tuning\n",
    "\n",
    "logParams = {'penalty': ['l1', 'l2'], \n",
    "            'C': [0.01, 0.1, 1],\n",
    "            'solver': ['liblinear']}\n",
    "\n",
    "logSearch = GridSearchCV(estimator = LogisticRegression(),  \n",
    "                           param_grid = logParams,\n",
    "                           scoring = 'recall',\n",
    "                           cv = 5,\n",
    "                           verbose=0,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "\n",
    "logSearch.fit(xTrainScaled, yTrainBalanced) \n",
    "\n",
    "logBestParams = logSearch.best_params_\n",
    "\n",
    "logBestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Hyperparameter Tuning\n",
    "\n",
    "svmParams = {'C':[1, 10, 100, 1000],\n",
    "            'gamma':[1, 0.1, 0.001, 0.0001], \n",
    "            'kernel':['linear','rbf']}\n",
    "\n",
    "svmSearch = GridSearchCV(estimator = SVC(),  \n",
    "                        param_grid = svmParams,\n",
    "                        scoring = 'recall',\n",
    "                        cv = 5,\n",
    "                        verbose=0,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "\n",
    "svmSearch.fit(xTrainScaled, yTrain) \n",
    "\n",
    "svmBestParams = svmSearch.best_params_\n",
    "\n",
    "svmBestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Hyperparameter Tuning\n",
    "\n",
    "mlpParams = {'max_iter': [1000],\n",
    "            'hidden_layer_sizes': [(50,50), (50,50,50), (100)],\n",
    "            'activation': ['relu'],\n",
    "            'solver': ['adam'],\n",
    "            'alpha': [0.0001, 0.05],\n",
    "            'learning_rate': ['constant','adaptive']}\n",
    "\n",
    "mlpSearch = GridSearchCV(estimator = MLPClassifier(),  \n",
    "                           param_grid = mlpParams,\n",
    "                           scoring = 'recall',\n",
    "                           cv = 5,\n",
    "                           verbose=0,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "\n",
    "mlpSearch.fit(xTrainScaled, yTrain) \n",
    "\n",
    "mlpBestParams = mlpSearch.best_params_\n",
    "\n",
    "mlpBestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Hyperparameter Tuning\n",
    "\n",
    "treeParams = {'criterion': ['gini', 'entropy'],\n",
    "              'splitter': ['best', 'random'],\n",
    "              'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'max_features': [None, 'sqrt', 'log2']}\n",
    "\n",
    "              \n",
    "treeSearch = GridSearchCV(estimator = DecisionTreeClassifier(),  \n",
    "                           param_grid = treeParams,\n",
    "                           scoring = 'recall',\n",
    "                           cv = 5,\n",
    "                           verbose=0,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "\n",
    "treeSearch.fit(xTrainScaled, yTrain) \n",
    "\n",
    "treeBestParams = treeSearch.best_params_\n",
    "\n",
    "treeBestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Hyperparameter Tuning\n",
    "\n",
    "rfParams = {'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_features': ['sqrt', 'log2', None]}\n",
    "\n",
    "rfSearch = GridSearchCV(estimator=RandomForestClassifier(),\n",
    "                             param_grid=rfParams,\n",
    "                             scoring='recall',\n",
    "                             cv=5,\n",
    "                             verbose=0,\n",
    "                             n_jobs=-1)  # Use all available CPUs\n",
    "\n",
    "rfSearch.fit(xTrainScaled, yTrain)\n",
    "\n",
    "rfBestParams = rfSearch.best_params_\n",
    "\n",
    "rfBestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnParams = {'n_neighbors': [3, 5, 7, 9, 11],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            'p': [1, 2]}\n",
    "\n",
    "knnSearch = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "                        param_grid=knnParams,\n",
    "                        scoring='recall',\n",
    "                        cv=5,\n",
    "                        verbose=0,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "knnSearch.fit(xTrainScaled, yTrain)\n",
    "\n",
    "knnBestParams = knnSearch.best_params_\n",
    "\n",
    "knnBestParams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Hyperparameter Tuning\n",
    "\n",
    "# Gradient Boosting model\n",
    "gbParams = {'n_estimators': [100, 200, 300], \n",
    "             'learning_rate': [0.01, 0.1, 0.5, 1], \n",
    "             'max_depth': [3, 4, 5, 6]}\n",
    "\n",
    "gbSearch = GridSearchCV(estimator=GradientBoostingClassifier(), \n",
    "                         param_grid= gbParams, \n",
    "                         scoring='recall', \n",
    "                         cv=5,\n",
    "                         verbose=0,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "gbSearch.fit(xTrainScaled, yTrainBalanced)\n",
    "\n",
    "gbBestParams = gbSearch.best_params_\n",
    "\n",
    "gbBestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracyScores = []\n",
    "f1Scores = []\n",
    "precisionScores = []\n",
    "recallScores = []\n",
    "aucScores = []\n",
    "\n",
    "for i, (trainIndex, valIndex) in enumerate(cv.split(xTrain, yTrain)):\n",
    "\n",
    "    ### making training and validation sets\n",
    "    # Convert indices to list\n",
    "    trainIndex = trainIndex.tolist()\n",
    "    valIndex = valIndex.tolist()\n",
    "    \n",
    "    # Split the data into training and validation sets for this fold\n",
    "    xLocalTrain, xVal = xTrain.iloc[trainIndex], xDF.iloc[valIndex]\n",
    "    yLocalTrain, yVal = yTrain.iloc[trainIndex], yDF.iloc[valIndex]\n",
    "\n",
    "\n",
    "    ### feature scaling\n",
    "    xScaler = StandardScaler()\n",
    "    xColNames = xLocalTrain.columns.values.tolist()\n",
    "    # train the scaler and apply it to the training set\n",
    "    xTrainScaled = xScaler.fit_transform(xLocalTrain[xColNames])\n",
    "    # apply the scaling to the validation set\n",
    "    xValScaled = xScaler.transform(xVal[xColNames])\n",
    "\n",
    "    ### model training\n",
    "    # instantiate the model\n",
    "    clf = LogisticRegression(**logisticParams)\n",
    "    # Train the classifier on the training data\n",
    "    clf.fit(xTrainScaled, yLocalTrain)\n",
    "    \n",
    "    ### model prediction and evaluation\n",
    "    # Make predictions on the test data\n",
    "    yPred = clf.predict(xValScaled)\n",
    "\n",
    "    # Calculate metrics and store them\n",
    "    score = accuracy_score(yVal, yPred)\n",
    "    accuracyScores.append(score)\n",
    "\n",
    "    score = f1_score(yVal, yPred)\n",
    "    f1Scores.append(score)\n",
    "\n",
    "    score = precision_score(yVal, yPred)\n",
    "    precisionScores.append(score)\n",
    "\n",
    "    score = recall_score(yVal, yPred)\n",
    "    recallScores.append(score)\n",
    "\n",
    "    print(f\"Completed Fold {i}\")\n",
    "    print(f\"    Accuracy={accuracyScores[i]}    Recall={recallScores[i]}    FScore={f1Scores[i]}\")\n",
    "\n",
    "## Calculate the mean scores across all folds\n",
    "mean_score = sum(accuracyScores) / len(accuracyScores)\n",
    "print(\"Mean accuracy score:\", mean_score)\n",
    "\n",
    "mean_score = sum(f1Scores) / len(f1Scores)\n",
    "print(\"Mean f1 score:\", mean_score)\n",
    "\n",
    "mean_score = sum(precisionScores) / len(precisionScores)\n",
    "print(\"Mean precision score:\", mean_score)\n",
    "\n",
    "mean_score = sum(recallScores) / len(recallScores)\n",
    "print(\"Mean recall score:\", mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracyScores = []\n",
    "f1Scores = []\n",
    "precisionScores = []\n",
    "recallScores = []\n",
    "aucScores = []\n",
    "\n",
    "for i, (trainIndex, valIndex) in enumerate(cv.split(xTrain, yTrain)):\n",
    "\n",
    "    ### making training and validation sets\n",
    "    # Convert indices to list\n",
    "    trainIndex = trainIndex.tolist()\n",
    "    valIndex = valIndex.tolist()\n",
    "    \n",
    "    # Split the data into training and validation sets for this fold\n",
    "    xLocalTrain, xVal = xTrain.iloc[trainIndex], xDF.iloc[valIndex]\n",
    "    yLocalTrain, yVal = yTrain.iloc[trainIndex], yDF.iloc[valIndex]\n",
    "\n",
    "\n",
    "    ### feature scaling\n",
    "    xScaler = StandardScaler()\n",
    "    xColNames = xLocalTrain.columns.values.tolist()\n",
    "    # train the scaler and apply it to the training set\n",
    "    xTrainScaled = xScaler.fit_transform(xLocalTrain[xColNames])\n",
    "    # apply the scaling to the validation set\n",
    "    xValScaled = xScaler.transform(xVal[xColNames])\n",
    "\n",
    "    ### model training\n",
    "    # instantiate the model\n",
    "    clf = DecisionTreeClassifier(**treeParams)\n",
    "    # Train the classifier on the training data\n",
    "    clf.fit(xTrainScaled, yLocalTrain)\n",
    "    \n",
    "    ### model prediction and evaluation\n",
    "    # Make predictions on the test data\n",
    "    yPred = clf.predict(xValScaled)\n",
    "\n",
    "    # Calculate metrics and store them\n",
    "    score = accuracy_score(yVal, yPred)\n",
    "    accuracyScores.append(score)\n",
    "\n",
    "    score = f1_score(yVal, yPred)\n",
    "    f1Scores.append(score)\n",
    "\n",
    "    score = precision_score(yVal, yPred)\n",
    "    precisionScores.append(score)\n",
    "\n",
    "    score = recall_score(yVal, yPred)\n",
    "    recallScores.append(score)\n",
    "\n",
    "    print(f\"Completed Fold {i}\")\n",
    "    print(f\"    Accuracy={accuracyScores[i]}    Recall={recallScores[i]}    FScore={f1Scores[i]}\")\n",
    "\n",
    "## Calculate the mean scores across all folds\n",
    "mean_score = sum(accuracyScores) / len(accuracyScores)\n",
    "print(\"Mean accuracy score:\", mean_score)\n",
    "\n",
    "mean_score = sum(f1Scores) / len(f1Scores)\n",
    "print(\"Mean f1 score:\", mean_score)\n",
    "\n",
    "mean_score = sum(precisionScores) / len(precisionScores)\n",
    "print(\"Mean precision score:\", mean_score)\n",
    "\n",
    "mean_score = sum(recallScores) / len(recallScores)\n",
    "print(\"Mean recall score:\", mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracyScores = []\n",
    "f1Scores = []\n",
    "precisionScores = []\n",
    "recallScores = []\n",
    "aucScores = []\n",
    "\n",
    "for i, (trainIndex, valIndex) in enumerate(cv.split(xTrain, yTrain)):\n",
    "\n",
    "    ### making training and validation sets\n",
    "    # Convert indices to list\n",
    "    trainIndex = trainIndex.tolist()\n",
    "    valIndex = valIndex.tolist()\n",
    "    \n",
    "    # Split the data into training and validation sets for this fold\n",
    "    xLocalTrain, xVal = xTrain.iloc[trainIndex], xDF.iloc[valIndex]\n",
    "    yLocalTrain, yVal = yTrain.iloc[trainIndex], yDF.iloc[valIndex]\n",
    "\n",
    "\n",
    "    ### feature scaling\n",
    "    xScaler = StandardScaler()\n",
    "    xColNames = xLocalTrain.columns.values.tolist()\n",
    "    # train the scaler and apply it to the training set\n",
    "    xTrainScaled = xScaler.fit_transform(xLocalTrain[xColNames])\n",
    "    # apply the scaling to the validation set\n",
    "    xValScaled = xScaler.transform(xVal[xColNames])\n",
    "\n",
    "    ### model training\n",
    "    # instantiate the model\n",
    "    clf = SVC(**svmParams)\n",
    "    # Train the classifier on the training data\n",
    "    clf.fit(xTrainScaled, yLocalTrain)\n",
    "    \n",
    "    ### model prediction and evaluation\n",
    "    # Make predictions on the test data\n",
    "    yPred = clf.predict(xValScaled)\n",
    "\n",
    "    # Calculate metrics and store them\n",
    "    score = accuracy_score(yVal, yPred)\n",
    "    accuracyScores.append(score)\n",
    "\n",
    "    score = f1_score(yVal, yPred)\n",
    "    f1Scores.append(score)\n",
    "\n",
    "    score = precision_score(yVal, yPred)\n",
    "    precisionScores.append(score)\n",
    "\n",
    "    score = recall_score(yVal, yPred)\n",
    "    recallScores.append(score)\n",
    "\n",
    "    print(f\"Completed Fold {i}\")\n",
    "    print(f\"    Accuracy={accuracyScores[i]}    Recall={recallScores[i]}    FScore={f1Scores[i]}\")\n",
    "\n",
    "## Calculate the mean scores across all folds\n",
    "mean_score = sum(accuracyScores) / len(accuracyScores)\n",
    "print(\"Mean accuracy score:\", mean_score)\n",
    "\n",
    "mean_score = sum(f1Scores) / len(f1Scores)\n",
    "print(\"Mean f1 score:\", mean_score)\n",
    "\n",
    "mean_score = sum(precisionScores) / len(precisionScores)\n",
    "print(\"Mean precision score:\", mean_score)\n",
    "\n",
    "mean_score = sum(recallScores) / len(recallScores)\n",
    "print(\"Mean recall score:\", mean_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracyScores = []\n",
    "f1Scores = []\n",
    "precisionScores = []\n",
    "recallScores = []\n",
    "aucScores = []\n",
    "\n",
    "for i, (trainIndex, valIndex) in enumerate(cv.split(xTrain, yTrain)):\n",
    "\n",
    "    ### making training and validation sets\n",
    "    # Convert indices to list\n",
    "    trainIndex = trainIndex.tolist()\n",
    "    valIndex = valIndex.tolist()\n",
    "    \n",
    "    # Split the data into training and validation sets for this fold\n",
    "    xLocalTrain, xVal = xTrain.iloc[trainIndex], xDF.iloc[valIndex]\n",
    "    yLocalTrain, yVal = yTrain.iloc[trainIndex], yDF.iloc[valIndex]\n",
    "\n",
    "\n",
    "    ### feature scaling\n",
    "    xScaler = StandardScaler()\n",
    "    xColNames = xLocalTrain.columns.values.tolist()\n",
    "    # train the scaler and apply it to the training set\n",
    "    xTrainScaled = xScaler.fit_transform(xLocalTrain[xColNames])\n",
    "    # apply the scaling to the validation set\n",
    "    xValScaled = xScaler.transform(xVal[xColNames])\n",
    "\n",
    "    ### model training\n",
    "    # instantiate the model\n",
    "    clf = MLPClassifier(**mlpParams)\n",
    "    # Train the classifier on the training data\n",
    "    clf.fit(xTrainScaled, yLocalTrain)\n",
    "    \n",
    "    ### model prediction and evaluation\n",
    "    # Make predictions on the test data\n",
    "    yPred = clf.predict(xValScaled)\n",
    "\n",
    "    # Calculate metrics and store them\n",
    "    score = accuracy_score(yVal, yPred)\n",
    "    accuracyScores.append(score)\n",
    "\n",
    "    score = f1_score(yVal, yPred)\n",
    "    f1Scores.append(score)\n",
    "\n",
    "    score = precision_score(yVal, yPred)\n",
    "    precisionScores.append(score)\n",
    "\n",
    "    score = recall_score(yVal, yPred)\n",
    "    recallScores.append(score)\n",
    "\n",
    "    print(f\"Completed Fold {i}\")\n",
    "    print(f\"    Accuracy={accuracyScores[i]}    Recall={recallScores[i]}    FScore={f1Scores[i]}\")\n",
    "\n",
    "## Calculate the mean scores across all folds\n",
    "mean_score = sum(accuracyScores) / len(accuracyScores)\n",
    "print(\"Mean accuracy score:\", mean_score)\n",
    "\n",
    "mean_score = sum(f1Scores) / len(f1Scores)\n",
    "print(\"Mean f1 score:\", mean_score)\n",
    "\n",
    "mean_score = sum(precisionScores) / len(precisionScores)\n",
    "print(\"Mean precision score:\", mean_score)\n",
    "\n",
    "mean_score = sum(recallScores) / len(recallScores)\n",
    "print(\"Mean recall score:\", mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "knn_accuracyScores = []\n",
    "knn_f1Scores = []\n",
    "knn_precisionScores = []\n",
    "knn_recallScores = []\n",
    "\n",
    "for i, (trainIndex, valIndex) in enumerate(cv.split(xTrain, yTrain)):\n",
    "    # Split the data\n",
    "    xLocalTrain, xVal = xTrain.iloc[trainIndex], xTrain.iloc[valIndex]\n",
    "    yLocalTrain, yVal = yTrain.iloc[trainIndex], yTrain.iloc[valIndex]\n",
    "\n",
    "    # Feature scaling\n",
    "    xScaler = StandardScaler()\n",
    "    xTrainScaled = xScaler.fit_transform(xLocalTrain)\n",
    "    xValScaled = xScaler.transform(xVal)\n",
    "\n",
    "    # Instantiate and train the KNN classifier\n",
    "    knn = KNeighborsClassifier(**knnParams)  # Assuming knnParams is predefined\n",
    "    knn.fit(xTrainScaled, yLocalTrain)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    yPred = knn.predict(xValScaled)\n",
    "    knn_accuracyScores.append(accuracy_score(yVal, yPred))\n",
    "    knn_f1Scores.append(f1_score(yVal, yPred))\n",
    "    knn_precisionScores.append(precision_score(yVal, yPred))\n",
    "    knn_recallScores.append(recall_score(yVal, yPred))\n",
    "\n",
    "    print(f\"Completed Fold {i}\")\n",
    "    print(f\"    Accuracy={knn_accuracyScores[i]}    Recall={knn_recallScores[i]}    FScore={knn_f1Scores[i]}\")\n",
    "\n",
    "# Calculate the mean scores across all folds for KNN\n",
    "print(\"KNN Mean accuracy score:\", np.mean(knn_accuracyScores))\n",
    "print(\"KNN Mean f1 score:\", np.mean(knn_f1Scores))\n",
    "print(\"KNN Mean precision score:\", np.mean(knn_precisionScores))\n",
    "print(\"KNN Mean recall score:\", np.mean(knn_recallScores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_accuracyScores = []\n",
    "rf_f1Scores = []\n",
    "rf_precisionScores = []\n",
    "rf_recallScores = []\n",
    "\n",
    "for i, (trainIndex, valIndex) in enumerate(cv.split(xTrain, yTrain)):\n",
    "    # Split the data\n",
    "    xLocalTrain, xVal = xTrain.iloc[trainIndex], xTrain.iloc[valIndex]\n",
    "    yLocalTrain, yVal = yTrain.iloc[trainIndex], yTrain.iloc[valIndex]\n",
    "\n",
    "    # Feature scaling (optional for RF but maintaining consistency)\n",
    "    xScaler = StandardScaler()\n",
    "    xTrainScaled = xScaler.fit_transform(xLocalTrain)\n",
    "    xValScaled = xScaler.transform(xVal)\n",
    "\n",
    "    # Instantiate and train the RF classifier\n",
    "    rf = RandomForestClassifier(**rfParams)  # Assuming rfParams is predefined\n",
    "    rf.fit(xTrainScaled, yLocalTrain)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    yPred = rf.predict(xValScaled)\n",
    "    rf_accuracyScores.append(accuracy_score(yVal, yPred))\n",
    "    rf_f1Scores.append(f1_score(yVal, yPred))\n",
    "    rf_precisionScores.append(precision_score(yVal, yPred))\n",
    "    rf_recallScores.append(recall_score(yVal, yPred))\n",
    "\n",
    "    print(f\"Completed Fold {i}\")\n",
    "    print(f\"    Accuracy={rf_accuracyScores[i]}    Recall={rf_recallScores[i]}    FScore={rf_f1Scores[i]}\")\n",
    "\n",
    "# Calculate the mean scores across all folds for RF\n",
    "print(\"RF Mean accuracy score:\", np.mean(rf_accuracyScores))\n",
    "print(\"RF Mean f1 score:\", np.mean(rf_f1Scores))\n",
    "print(\"RF Mean precision score:\", np.mean(rf_precisionScores))\n",
    "print(\"RF Mean recall score:\", np.mean(rf_recallScores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### feature scaling\n",
    "xScaler = StandardScaler()\n",
    "xColNames = xLocalTrain.columns.values.tolist()\n",
    "# train the scaler and apply it to the training set\n",
    "xTrainScaled = xScaler.fit_transform(xTrain[xColNames])\n",
    "# apply the scaling to the testing set\n",
    "xTestScaled = xScaler.transform(xTest[xColNames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ \n",
    "# Logistic Regression\n",
    "################\n",
    "clf = LogisticRegression(**logisticParams)\n",
    "clf.fit(xTrainScaled, yTrain)\n",
    "\n",
    "preds = clf.predict(xTestScaled)\n",
    "\n",
    "lrAccuracy = accuracy_score(yTest, preds)\n",
    "lrFScore = f1_score(yTest, preds)\n",
    "lrPrecision = precision_score(yTest, preds)\n",
    "lrRecall = recall_score(yTest, preds)\n",
    "\n",
    "################ \n",
    "# Neural Net\n",
    "################\n",
    "clf = MLPClassifier(**mlpParams)\n",
    "clf.fit(xTrainScaled, yTrain)\n",
    "\n",
    "preds = clf.predict(xTestScaled)\n",
    "\n",
    "nnAccuracy = accuracy_score(yTest, preds)\n",
    "nnFScore = f1_score(yTest, preds)\n",
    "nnPrecision = precision_score(yTest, preds)\n",
    "nnRecall = recall_score(yTest, preds)\n",
    "\n",
    "################ \n",
    "# Decision Tree\n",
    "################\n",
    "clf = DecisionTreeClassifier(**treeParams)\n",
    "clf.fit(xTrainScaled, yTrain)\n",
    "\n",
    "preds = clf.predict(xTestScaled)\n",
    "\n",
    "treeAccuracy = accuracy_score(yTest, preds)\n",
    "treeFScore = f1_score(yTest, preds)\n",
    "treePrecision = precision_score(yTest, preds)\n",
    "treeRecall = recall_score(yTest, preds)\n",
    "\n",
    "################ \n",
    "# Random Forest\n",
    "################\n",
    "clf = RandomForestClassifier(**rfParams)\n",
    "clf.fit(xTrainScaled, yTrain)\n",
    "\n",
    "preds = clf.predict(xTestScaled)\n",
    "\n",
    "rfAccuracy = accuracy_score(yTest, preds)\n",
    "rfFScore = f1_score(yTest, preds)\n",
    "rfPrecision = precision_score(yTest, preds)\n",
    "rfRecall = recall_score(yTest, preds)\n",
    "\n",
    "################ \n",
    "# K-NN\n",
    "################\n",
    "clf = KNeighborsClassifier(**knnParams)\n",
    "clf.fit(xTrainScaled, yTrain)\n",
    "\n",
    "preds = clf.predict(xTestScaled)\n",
    "\n",
    "knnAccuracy = accuracy_score(yTest, preds)\n",
    "knnFScore = f1_score(yTest, preds)\n",
    "knnPrecision = precision_score(yTest, preds)\n",
    "knnRecall = recall_score(yTest, preds)\n",
    "\n",
    "################ \n",
    "# SVM\n",
    "################\n",
    "\n",
    "clf = SVC(**svmParams)\n",
    "clf.fit(xTrainScaled, yTrain)\n",
    "\n",
    "preds = clf.predict(xTestScaled)\n",
    "\n",
    "svmAccuracy = accuracy_score(yTest, preds)\n",
    "svmFScore = f1_score(yTest, preds)\n",
    "svmPrecision = precision_score(yTest, preds)\n",
    "svmRecall = recall_score(yTest, preds)\n",
    "\n",
    "scoreDict = {\"model\" : [\"Neural Network\", \"SVM\", \"K-NN\", \"Decision Tree\", \"RF\", \"LR\"],\n",
    "            \"accuracy\" : [nnAccuracy, svmAccuracy, knnAccuracy, treeAccuracy, rfAccuracy, lrAccuracy],\n",
    "            \"fScore\" : [nnFScore, svmFScore, knnFScore, treeFScore, rfFScore, lrFScore],\n",
    "            \"precision\" : [nnPrecision, svmPrecision, knnPrecision, treePrecision, rfPrecision, lrPrecision],\n",
    "            \"recall\" : [nnRecall, svmRecall, knnRecall, treeRecall, rfRecall, lrRecall]}\n",
    "\n",
    "resultsDF = pd.DataFrame.from_dict(scoreDict)\n",
    "\n",
    "resultsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_results = resultsDF.style.set_table_styles(\n",
    "    [{'selector': 'th', 'props': [('font-size', '14pt'), ('text-align', 'center'), ('color', 'black')]},\n",
    "     {'selector': 'td', 'props': [('text-align', 'center'), ('color', 'black')]},\n",
    "     {'selector': 'tr:nth-of-type(odd)', 'props': [('background', '#f5f5f5')]},\n",
    "     {'selector': 'tr:nth-of-type(even)', 'props': [('background', 'white')]},\n",
    "     {'selector': 'tr:hover', 'props': [('background-color', '#ffff99')]},\n",
    "    ], overwrite=False)\n",
    "\n",
    "styled_results = styled_results.format({\n",
    "    'accuracy': '{:,.2f}'.format,\n",
    "    'fScore': '{:,.2f}'.format,\n",
    "    'precision': '{:,.2f}'.format,\n",
    "    'recall': '{:,.2f}'.format\n",
    "})\n",
    "\n",
    "styled_results = styled_results.hide()\n",
    "\n",
    "styled_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
