{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Read in the data\n",
    "rawDF = pd.read_csv(\"Cancer_Data.csv\")\n",
    "\n",
    "# Take a peek at the data\n",
    "rawDF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'id' column as its useless to us\n",
    "rawDF = rawDF.drop([\"Unnamed: 32\",\"id\"], axis = 1)\n",
    "\n",
    "# Let's also change diagnosis into a numeric binary variable\n",
    "rawDF.diagnosis = [1 if each == \"M\" else 0 for each in rawDF.diagnosis]\n",
    "\n",
    "# Let's take a deeper look at the data and use the describe function\n",
    "rawDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also use a for loop to check for NA values\n",
    "for col in rawDF:\n",
    "    naCount = rawDF[col].isna().sum()\n",
    "    print(f\"The number of NA values in the {col} col is {naCount}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Functions\n",
    "\n",
    "# This function generates histograms for each feature to show the distribution of the data\n",
    "def generateHistograms(rawDF, column_names):\n",
    "    n_cols = 5\n",
    "    n_rows = (len(column_names) + n_cols - 1) // n_cols\n",
    "    axs = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 5))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for i, col in enumerate(column_names):\n",
    "        axs[i].hist(rawDF[col].dropna(), bins=15)\n",
    "        axs[i].set_xlabel(col, labelpad=14)\n",
    "        axs[i].set_ylabel(\"Frequency\", labelpad=14)\n",
    "        axs[i].set_title(f\"Distribution of {col}\")\n",
    "\n",
    "    for j in range(i + 1, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# This function generates boxplots for each feature to show outliers\n",
    "# That said, we may not need to worry about outliers in the context of this data\n",
    "def generateBoxplots(rawDF, column_names):\n",
    "    n_cols = 5\n",
    "    n_rows = (len(column_names) + n_cols - 1) // n_cols\n",
    "    axs = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 5))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for i, col in enumerate(column_names):\n",
    "        sns.boxplot(x=rawDF[col], ax=axs[i])\n",
    "        axs[i].set_title(f\"Boxplot of {col}\")\n",
    "\n",
    "    for j in range(i + 1, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "columns_to_plot = rawDF.columns.drop('diagnosis')\n",
    "generateHistograms(rawDF, columns_to_plot)\n",
    "generateBoxplots(rawDF, columns_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triangle Correlation Heatmap\n",
    "plt.figure(figsize=(20, 8))\n",
    "mask = np.triu(np.ones_like(rawDF.corr(), dtype=bool))\n",
    "heatmap = sns.heatmap(rawDF.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "heatmap.set_title('Triangle Correlation Heatmap', fontdict={'fontsize':18}, pad=16)\n",
    "plt.savefig('heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "\n",
    "yDF = rawDF[\"diagnosis\"]\n",
    "xDF = rawDF.drop(columns=[\"diagnosis\"], axis=1)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(\n",
    "    xDF, yDF, \n",
    "    test_size=0.05,\n",
    "    shuffle = True,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include SMOTE to handle class imbalance\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "xTrainBalanced, yTrainBalanced = smote.fit_resample(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "\n",
    "select = SelectKBest(f_classif, k=25)\n",
    "xTrainSelect = select.fit_transform(xTrainBalanced, yTrainBalanced)\n",
    "xTestSelect = select.transform(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "\n",
    "xScaler = StandardScaler()\n",
    "xTrainScaled = xScaler.fit_transform(xTrainBalanced, yTrainBalanced)\n",
    "xTestScaled = xScaler.transform(xTestSelect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Hyperparameter Tuning\n",
    "\n",
    "logParams = {'penalty': ['l1', 'l2'], \n",
    "            'C': [0.01, 0.1, 1],\n",
    "            'solver': ['liblinear']}\n",
    "\n",
    "logSearch = GridSearchCV(estimator = LogisticRegression(),  \n",
    "                           param_grid = logParams,\n",
    "                           scoring = 'recall',\n",
    "                           cv = 5,\n",
    "                           verbose=0,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "\n",
    "logSearch.fit(xTrainScaled, yTrainBalanced) \n",
    "\n",
    "logBestParams = logSearch.best_params_\n",
    "\n",
    "logBestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Hyperparameter Tuning\n",
    "\n",
    "svmParams = {'C':[1, 10, 100, 1000],\n",
    "            'gamma':[1, 0.1, 0.001, 0.0001], \n",
    "            'kernel':['linear','rbf']}\n",
    "\n",
    "svmSearch = GridSearchCV(estimator = SVC(),  \n",
    "                        param_grid = svmParams,\n",
    "                        scoring = 'recall',\n",
    "                        cv = 5,\n",
    "                        verbose=0,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "\n",
    "svmSearch.fit(xTrainScaled, yTrain) \n",
    "\n",
    "svmBestParams = svmSearch.best_params_\n",
    "\n",
    "svmBestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Hyperparameter Tuning\n",
    "\n",
    "mlpParams = {'max_iter': [1000],\n",
    "            'hidden_layer_sizes': [(50,50), (50,50,50), (100)],\n",
    "            'activation': ['relu'],\n",
    "            'solver': ['adam'],\n",
    "            'alpha': [0.0001, 0.05],\n",
    "            'learning_rate': ['constant','adaptive']}\n",
    "\n",
    "mlpSearch = GridSearchCV(estimator = MLPClassifier(),  \n",
    "                           param_grid = mlpParams,\n",
    "                           scoring = 'recall',\n",
    "                           cv = 5,\n",
    "                           verbose=0,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "\n",
    "mlpSearch.fit(xTrainScaled, yTrain) \n",
    "\n",
    "mlpBestParams = mlpSearch.best_params_\n",
    "\n",
    "mlpBestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Hyperparameter Tuning\n",
    "\n",
    "treeParams = {'criterion': ['gini', 'entropy'],\n",
    "              'splitter': ['best', 'random'],\n",
    "              'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'max_features': [None, 'sqrt', 'log2']}\n",
    "\n",
    "              \n",
    "treeSearch = GridSearchCV(estimator = DecisionTreeClassifier(),  \n",
    "                           param_grid = treeParams,\n",
    "                           scoring = 'recall',\n",
    "                           cv = 5,\n",
    "                           verbose=0,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "\n",
    "treeSearch.fit(xTrainScaled, yTrain) \n",
    "\n",
    "treeBestParams = treeSearch.best_params_\n",
    "\n",
    "treeBestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Hyperparameter Tuning\n",
    "\n",
    "rfParams = {'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_features': ['sqrt', 'log2', None]}\n",
    "\n",
    "rfSearch = GridSearchCV(estimator=RandomForestClassifier(),\n",
    "                             param_grid=rfParams,\n",
    "                             scoring='recall',\n",
    "                             cv=5,\n",
    "                             verbose=0,\n",
    "                             n_jobs=-1)  # Use all available CPUs\n",
    "\n",
    "rfSearch.fit(xTrainScaled, yTrain)\n",
    "\n",
    "rfBestParams = rfSearch.best_params_\n",
    "\n",
    "rfBestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnParams = {'n_neighbors': [3, 5, 7, 9, 11],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "            'p': [1, 2]}\n",
    "\n",
    "knnSearch = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "                        param_grid=knnParams,\n",
    "                        scoring='recall',\n",
    "                        cv=5,\n",
    "                        verbose=0,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "knnSearch.fit(xTrainScaled, yTrain)\n",
    "\n",
    "knnBestParams = knnSearch.best_params_\n",
    "\n",
    "knnBestParams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Hyperparameter Tuning\n",
    "\n",
    "# Gradient Boosting model\n",
    "gbParams = {'n_estimators': [100, 200, 300], \n",
    "             'learning_rate': [0.01, 0.1, 0.5, 1], \n",
    "             'max_depth': [3, 4, 5, 6]}\n",
    "\n",
    "gbSearch = GridSearchCV(estimator=GradientBoostingClassifier(), \n",
    "                         param_grid= gbParams, \n",
    "                         scoring='recall', \n",
    "                         cv=5,\n",
    "                         verbose=0,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "gbSearch.fit(xTrainScaled, yTrainBalanced)\n",
    "\n",
    "gbBestParams = gbSearch.best_params_\n",
    "\n",
    "gbBestParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation function\n",
    "def crossValidate(clf, xTrain, yTrain, params, cv=5):\n",
    "    cv = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    accuracyScores, f1Scores, precisionScores, recallScores = [], [], [], []\n",
    "\n",
    "    for i, (trainIndex, valIndex) in enumerate(cv.split(xTrain, yTrain)):\n",
    "        xLocalTrain, xVal = xTrain[trainIndex], xTrain[valIndex]\n",
    "        yLocalTrain, yVal = yTrain[trainIndex], yTrain[valIndex]\n",
    "\n",
    "        model = clf(**params)\n",
    "        model.fit(xLocalTrain, yLocalTrain)\n",
    "\n",
    "        yPred = model.predict(xVal)\n",
    "\n",
    "        accuracyScores.append(accuracy_score(yVal, yPred))\n",
    "        f1Scores.append(f1_score(yVal, yPred))\n",
    "        precisionScores.append(precision_score(yVal, yPred))\n",
    "        recallScores.append(recall_score(yVal, yPred))\n",
    "\n",
    "        print(f\"Completed Fold {i}\")\n",
    "        print(f\"    Accuracy={accuracyScores[i]}    Recall={recallScores[i]}    f1Score={f1Scores[i]}\")\n",
    "\n",
    "    print(\"Mean accuracy score:\", np.mean(accuracyScores))\n",
    "    print(\"Mean f1Score:\", np.mean(f1Scores))\n",
    "    print(\"Mean precision score:\", np.mean(precisionScores))\n",
    "    print(\"Mean recall score:\", np.mean(recallScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate models\n",
    "crossValidate(LogisticRegression, xTrainScaled, yTrainBalanced, logBestParams)\n",
    "crossValidate(SVC, xTrainScaled, yTrainBalanced, svmBestParams)\n",
    "crossValidate(MLPClassifier, xTrainScaled, yTrainBalanced, mlpBestParams)\n",
    "crossValidate(DecisionTreeClassifier, xTrainScaled, yTrainBalanced, treeBestParams)\n",
    "crossValidate(RandomForestClassifier, xTrainScaled, yTrainBalanced, rfBestParams)\n",
    "crossValidate(KNeighborsClassifier, xTrainScaled, yTrainBalanced, knnBestParams)\n",
    "crossValidate(GradientBoostingClassifier, xTrainScaled, yTrainBalanced, gbBestParams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
